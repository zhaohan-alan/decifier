{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1636a4-9222-4c1c-83f0-9dbbc174b681",
   "metadata": {},
   "source": [
    "# deCIFer: Validity Assessment of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795bd636-7349-421a-b874-f6a5efa33135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "from queue import Empty\n",
    "from queue import Empty\n",
    "from glob import glob\n",
    "import pickle\n",
    "import gzip\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "from warnings import warn\n",
    "\n",
    "# Third-party library imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from pymatgen.io.cif import CifParser\n",
    "from pymatgen.analysis.structure_matcher import StructureMatcher\n",
    "\n",
    "# Conditional imports for backwards compatibility with older pymatgen versions\n",
    "try:\n",
    "    parser_from_string = CifParser.from_str\n",
    "except AttributeError:\n",
    "    parser_from_string = CifParser.from_string\n",
    "\n",
    "from decifer.decifer_model import Decifer, DeciferConfig\n",
    "from decifer.decifer_dataset import DeciferDataset\n",
    "from decifer.tokenizer import Tokenizer\n",
    "from bin.evaluate import load_model_from_checkpoint, get_cif_statistics, safe_extract, safe_extract_boolean\n",
    "from decifer.utility import (\n",
    "    get_rmsd,\n",
    "    replace_symmetry_loop_with_P1,\n",
    "    extract_space_group_symbol,\n",
    "    reinstate_symmetry_loop,\n",
    "    is_sensible,\n",
    "    extract_numeric_property,\n",
    "    get_unit_cell_volume,\n",
    "    extract_volume,\n",
    "    is_space_group_consistent,\n",
    "    is_atom_site_multiplicity_consistent,\n",
    "    is_formula_consistent,\n",
    "    bond_length_reasonableness_score,\n",
    "    extract_species,\n",
    "    discrete_to_continuous_xrd,\n",
    "    generate_continuous_xrd_from_cif,\n",
    ")\n",
    "from bin.train import TrainConfig\n",
    "\n",
    "# Tokenizer, get start, padding and newline IDs\n",
    "TOKENIZER = Tokenizer()\n",
    "VOCAB_SIZE = TOKENIZER.vocab_size\n",
    "START_ID = TOKENIZER.token_to_id[\"data_\"]\n",
    "PADDING_ID = TOKENIZER.padding_id\n",
    "NEWLINE_ID = TOKENIZER.token_to_id[\"\\n\"]\n",
    "SPACEGROUP_ID = TOKENIZER.token_to_id[\"_symmetry_space_group_name_H-M\"]\n",
    "DECODE = TOKENIZER.decode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf13cc7-ab27-4640-a713-9b856d696522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Define dataset path and initialize dataset\n",
    "dataset_path = '../data/chili100k/full/serialized/train.h'\n",
    "dataset = DeciferDataset(dataset_path, [\"cif_name\", \"cif_tokens\", \"xrd.q\", \"xrd.iq\", \"cif_string\", \"spacegroup\"])\n",
    "\n",
    "num_generations = 5000\n",
    "pbar = tqdm(total=num_generations)\n",
    "\n",
    "# Helper function to process a single data point\n",
    "def process_data(data):\n",
    "    cif_string = data['cif_string']\n",
    "    try:\n",
    "        sg = is_space_group_consistent(cif_string)\n",
    "        form = is_formula_consistent(cif_string)\n",
    "        sm = is_atom_site_multiplicity_consistent(cif_string)\n",
    "        bl = bond_length_reasonableness_score(cif_string) >= 1.0\n",
    "        valid = form and sm and bl and sg\n",
    "    except ZeroDivisionError:\n",
    "        form, sm, bl, sg, valid = False, False, False, False, False\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "        form, sm, bl, sg, valid = False, False, False, False, False\n",
    "\n",
    "    return form, sm, bl, sg, valid\n",
    "\n",
    "# Wrap dataset generation for multiprocessing compatibility\n",
    "def dataset_generator():\n",
    "    for _, data in zip(range(num_generations), dataset):\n",
    "        yield data\n",
    "\n",
    "num_cores = 7\n",
    "with Pool(processes=num_cores) as pool:\n",
    "    results = []\n",
    "    for result in pool.imap_unordered(process_data, dataset_generator(), chunksize=10):\n",
    "        results.append(result)\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "# Unpack results\n",
    "forms, sms, bls, sgs, valids = zip(*results)\n",
    "\n",
    "# Calculate percentages\n",
    "form_percent = (sum(forms) / num_generations) * 100\n",
    "sm_percent = (sum(sms) / num_generations) * 100\n",
    "bl_percent = (sum(bls) / num_generations) * 100\n",
    "sg_percent = (sum(sgs) / num_generations) * 100\n",
    "valid_percent = (sum(valids) / num_generations) * 100\n",
    "\n",
    "# Print summarized results\n",
    "print(\"Summary of Validity Checks:\")\n",
    "print(f\"Formulas: {form_percent:.2f}% valid\")\n",
    "print(f\"Site Multiplicities: {sm_percent:.2f}% valid\")\n",
    "print(f\"Bond Lengths: {bl_percent:.2f}% valid\")\n",
    "print(f\"Spacegroups: {sg_percent:.2f}% valid\")\n",
    "print(f\"Overall Valid: {valid_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980e59c-6474-405d-ba56-55f59945508e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
